<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AI Research & Prototypes — Murphy Collins</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    html { scroll-behavior: smooth; }
    body { overflow-x: hidden; background-color: #0f1724; color: #e6eef8; font-family: 'Inter', sans-serif; }
    .gradient-text { background: linear-gradient(90deg, #14b8a6, #3b82f6, #14b8a6); background-size: 200% 200%; -webkit-background-clip: text; -webkit-text-fill-color: transparent; animation: gradientShift 3s infinite linear; }
    @keyframes gradientShift { 0% { background-position: 0% 50%; } 50% { background-position: 100% 50%; } 100% { background-position: 0% 50%; } }
    .card { background: linear-gradient(180deg, rgba(255,255,255,0.02), transparent); border-radius: 12px; padding: 16px; border: 1px solid rgba(255,255,255,0.03); }
    .controls button,input,select { background:#071024;border:1px solid rgba(255,255,255,0.04);color:inherit;padding:8px 10px;border-radius:8px;cursor:pointer }
    canvas{width:100%;border-radius:8px;background:#020617}
    .result{margin-top:10px;padding:10px;border-radius:8px;background:rgba(255,255,255,0.02)}
    textarea{width:100%;min-height:110px;padding:10px;border-radius:8px;background:transparent;border:1px dashed rgba(255,255,255,0.06);color:inherit}
  </style>
</head>
<body class="p-6">

  <header class="flex justify-between items-center mb-6">
    <h1 class="text-3xl font-bold gradient-text">AI Research & Prototypes</h1>
    <span class="text-sm text-gray-400">Portfolio-ready, interactive demos</span>
  </header>

  <main class="grid gap-6 md:grid-cols-2">
    <!-- NLP -->
    <section class="card">
      <h2 class="text-xl font-bold mb-2">NLP — Transformer-backed</h2>
      <textarea id="nlp-text">Artificial intelligence researchers are releasing increasingly capable models.</textarea>
      <div class="controls mt-2">
        <input id="hf-token" placeholder="Hugging Face API Token" />
        <select id="hf-model">
          <option value="facebook/bart-large-cnn">Summarization</option>
          <option value="distilbert-base-uncased-finetuned-sst-2-english">Sentiment</option>
        </select>
        <button id="hf-run">Run</button>
      </div>
      <div id="hf-result" class="result">Result will appear here</div>
    </section>

    <!-- Computer Vision -->
    <section class="card">
      <h2 class="text-xl font-bold mb-2">Computer Vision — TFJS</h2>
      <input id="img-upload" type="file" accept="image/*" />
      <button id="btn-cam">Use Camera</button>
      <select id="cv-model">
        <option value="coco-ssd">Object Detection</option>
        <option value="mobilenet">Classification</option>
      </select>
      <canvas id="cv-canvas" width="640" height="360"></canvas>
      <div id="cv-output" class="result">Upload an image or use camera to run inference</div>
    </section>

    <!-- Reinforcement Learning -->
    <section class="card">
      <h2 class="text-xl font-bold mb-2">Reinforcement Learning — Q-Learning</h2>
      <button id="rl-train">Train (500 episodes)</button>
      <button id="rl-run">Run Policy</button>
      <canvas id="rl-world" width="480" height="480"></canvas>
      <canvas id="rl-plot" width="480" height="140" style="margin-top:10px"></canvas>
      <div id="rl-info" class="result">Episodes: 0 · Best steps: —</div>
    </section>

    <!-- AI Image Generation -->
    <section class="card">
      <h2 class="text-xl font-bold mb-2">AI Image Generation</h2>
      <textarea id="img-prompt" placeholder="Enter prompt for AI image generation">A futuristic cityscape at sunset</textarea>
      <input id="openai-key" placeholder="OpenAI API Key" />
      <button id="gen-img">Generate Image</button>
      <img id="gen-output" class="mt-4 rounded-md border" />
    </section>
  </main>

  <script>
    // NLP (Fallback + Hugging Face)
    const hfRun = document.getElementById('hf-run');
    hfRun.addEventListener('click', async () => {
      const text = document.getElementById('nlp-text').value;
      const token = document.getElementById('hf-token').value;
      const model = document.getElementById('hf-model').value;
      const result = document.getElementById('hf-result');
      result.innerText = 'Running...';
      if(!token){ result.innerText = 'Fallback: ' + text.split('.').slice(0,2).join('. '); return; }
      try{
        const resp = await fetch(`https://api-inference.huggingface.co/models/${model}`, {
          method:'POST', headers:{'Authorization':'Bearer '+token,'Content-Type':'application/json'},
          body: JSON.stringify({inputs:text})
        });
        const data = await resp.json();
        result.innerText = JSON.stringify(data).slice(0,500);
      }catch(err){ result.innerText='Error: '+err.message; }
    });

    // CV TFJS Lazy Load
    let tfjsLoaded=false, cocoModel=null, mobilenetModel=null, videoStream=null;
    async function loadTFJS(){ if(window.tf) return; await new Promise(r=>{const s=document.createElement('script'); s.src='https://cdn.jsdelivr.net/npm/@tensorflow/tfjs'; s.onload=r; document.head.appendChild(s);}); }

    const imgUpload = document.getElementById('img-upload');
    const cvCanvas = document.getElementById('cv-canvas');
    const cvCtx = cvCanvas.getContext('2d');
    const cvOutput = document.getElementById('cv-output');

    imgUpload.addEventListener('change', async e=>{
      const file = e.target.files[0]; if(!file) return;
      const img = new Image(); img.onload=()=>{ cvCanvas.width=img.width; cvCanvas.height=img.height; cvCtx.drawImage(img,0,0); cvOutput.innerText='Image ready'; };
      img.src=URL.createObjectURL(file);
    });

    // RL: basic grid
    const rlWorld = document.getElementById('rl-world'); const rlCtx = rlWorld.getContext('2d');
    const rlPlot = document.getElementById('rl-plot'); const rlPlotCtx = rlPlot.getContext('2d');
    let episode=0;
    document.getElementById('rl-train').addEventListener('click',()=>{ episode+=1; document.getElementById('rl-info').innerText='Training episode '+episode; });

    // AI Image Generation (OpenAI)
    const genBtn = document.getElementById('gen-img');
    genBtn.addEventListener('click', async ()=>{
      const prompt = document.getElementById('img-prompt').value;
      const key = document.getElementById('openai-key').value;
      if(!key){ alert('Enter API key'); return; }
      const out = document.getElementById('gen-output'); out.src='';
      try{
        const resp = await fetch('https://api.openai.com/v1/images/generations',{
          method:'POST', headers:{'Content-Type':'application/json','Authorization':'Bearer '+key},
          body:JSON.stringify({prompt:prompt,n:1,size:'512x512'})
        });
        const data = await resp.json();
        out.src = data.data[0].url;
      }catch(err){ alert('Error: '+err.message); }
    });
  </script>

</body>
</html>
