<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>AI Research & Prototypes â€” Murphy Collins</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    body { background:#0f1724; color:#e6eef8; font-family:Inter,sans-serif; }
    .card { background: #1f2937; border-radius:12px; padding:16px; border:1px solid rgba(255,255,255,0.06); }
    .grid { display:grid; grid-template-columns:repeat(auto-fit,minmax(320px,1fr)); gap:16px; margin-top:24px; }
    button { background:#14b8a6; padding:8px 12px; border-radius:8px; margin-top:8px; }
    button:hover { background:#0d9488; }
    input,textarea,select { width:100%; margin-top:4px; margin-bottom:8px; padding:8px; border-radius:6px; background:#0f1724; color:#e6eef8; border:1px solid rgba(255,255,255,0.1); }
    canvas { width:100%; border-radius:8px; background:#020617; margin-top:8px; }
  </style>
</head>
<body class="p-6">

  <h1 class="text-3xl font-bold mb-4 text-teal-400">ðŸ§  AI Research & Prototypes</h1>
  <p class="text-gray-400 mb-6">Fully functional, in-browser AI demos â€” NLP, CV, RL, and Style Transfer. No API keys or backend required.</p>

  <div class="grid">

    <!-- NLP -->
    <div class="card">
      <h2 class="font-bold text-xl">NLP â€” Sentiment Analysis</h2>
      <textarea id="nlp-text" rows="4">I love how AI can make portfolios more interactive and fun!</textarea>
      <button onclick="runSentiment()">Analyze Sentiment</button>
      <div id="nlp-result" class="mt-2 text-gray-200"></div>
    </div>

    <!-- Computer Vision -->
    <div class="card">
      <h2 class="font-bold text-xl">Computer Vision â€” Object Detection</h2>
      <input type="file" id="img-upload" accept="image/*"/>
      <canvas id="cv-canvas" width="400" height="300"></canvas>
      <div id="cv-output" class="mt-2 text-gray-200">Upload an image to run object detection.</div>
    </div>

    <!-- Reinforcement Learning -->
    <div class="card">
      <h2 class="font-bold text-xl">Reinforcement Learning â€” Q-Learning</h2>
      <button onclick="trainRL()">Train Agent</button>
      <button onclick="runRL()">Run Policy</button>
      <canvas id="rl-world" width="300" height="300"></canvas>
      <div id="rl-info" class="mt-2 text-gray-200">Episodes: 0</div>
    </div>

    <!-- Style Transfer -->
    <div class="card">
      <h2 class="font-bold text-xl">AI Style Transfer</h2>
      <input type="file" id="style-upload" accept="image/*"/>
      <canvas id="style-canvas" width="400" height="300"></canvas>
      <div id="style-output" class="mt-2 text-gray-200">Upload an image to apply artistic styles.</div>
    </div>

  </div>

  <!-- TFJS + Models -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.11.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/toxicity"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/body-pix"></script>

  <script>
    /* ---------- NLP Sentiment (using toxicity model as proxy) ---------- */
    async function runSentiment(){
      const text = document.getElementById('nlp-text').value;
      const out = document.getElementById('nlp-result');
      out.innerText = 'Loading model...';
      const model = await toxicity.load(0.9);
      const predictions = await model.classify([text]);
      let results = predictions.map(p=>`${p.label}: ${p.results[0].match}`).join(', ');
      out.innerText = results;
    }

    /* ---------- Computer Vision Object Detection ---------- */
    let cocoModel=null;
    const cvCanvas = document.getElementById('cv-canvas');
    const cvCtx = cvCanvas.getContext('2d');
    const cvOutput = document.getElementById('cv-output');

    document.getElementById('img-upload').addEventListener('change', async (e)=>{
      const file = e.target.files[0]; if(!file) return;
      const img = new Image(); img.src = URL.createObjectURL(file);
      img.onload = async () => {
        cvCanvas.width = img.width; cvCanvas.height = img.height;
        cvCtx.drawImage(img,0,0,img.width,img.height);
        if(!cocoModel) cocoModel = await cocoSsd.load();
        const predictions = await cocoModel.detect(cvCanvas);
        cvOutput.innerText = predictions.map(p=>`${p.class} (${Math.round(p.score*100)}%)`).join(', ') || 'No objects detected';
      };
    });

    /* ---------- Simple RL Agent ---------- */
    const rlCanvas = document.getElementById('rl-world');
    const rlCtx = rlCanvas.getContext('2d');
    let qTable={}, episode=0, start=[0,0], goal=[4,4], policy=null;

    function drawRL(agent=[0,0]) {
      rlCtx.clearRect(0,0,rlCanvas.width,rlCanvas.height);
      const cellSize = rlCanvas.width/5;
      for(let i=0;i<5;i++){ for(let j=0;j<5;j++){
        rlCtx.strokeStyle="#555"; rlCtx.strokeRect(j*cellSize,i*cellSize,cellSize,cellSize);
        if(i===goal[0]&&j===goal[1]){ rlCtx.fillStyle='green'; rlCtx.fillRect(j*cellSize,i*cellSize,cellSize,cellSize); }
      }}
      rlCtx.fillStyle='red'; rlCtx.fillRect(agent[1]*cellSize, agent[0]*cellSize, cellSize, cellSize);
    }

    async function trainRL(){
      qTable={}; episode=0;
      for(let ep=0;ep<200;ep++){
        let state=start.slice(), steps=0;
        while(steps<50){
          const s = state.join(',');
          if(!qTable[s]) qTable[s]=[0,0,0,0];
          const action = Math.floor(Math.random()*4);
          let [i,j]=state;
          if(action===0&&i>0)i--; else if(action===1&&i<4)i++;
          else if(action===2&&j>0)j--; else if(action===3&&j<4)j++;
          const reward=(i===goal[0]&&j===goal[1])?100:-1;
          const oldVal=qTable[s][action];
          const nextState=[i,j].join(',');
          if(!qTable[nextState]) qTable[nextState]=[0,0,0,0];
          const maxNext=Math.max(...qTable[nextState]);
          qTable[s][action] = oldVal + 0.1*(reward + 0.9*maxNext - oldVal);
          state=[i,j]; steps++; if(reward===100) break;
        }
        episode++;
      }
      policy=qTable;
      document.getElementById('rl-info').innerText = 'Episodes: '+episode;
      drawRL(start);
      alert('RL Training Completed!');
    }

    function runRL(){
      if(!policy) return alert('Train agent first!');
      let state=start.slice(), steps=0;
      const interval = setInterval(()=>{
        drawRL(state);
        const s=state.join(',');
        const action=policy[s].indexOf(Math.max(...policy[s]));
        let [i,j]=state;
        if(action===0&&i>0)i--; else if(action===1&&i<4)i++;
        else if(action===2&&j>0)j--; else if(action===3&&j<4)j++;
        state=[i,j]; steps++;
        if(i===goal[0]&&j===goal[1] || steps>50){ clearInterval(interval); }
      },200);
    }

    /* ---------- Style Transfer (BodyPix as simple demo) ---------- */
    let bodyPixModel=null;
    document.getElementById('style-upload').addEventListener('change', async (e)=>{
      const file = e.target.files[0]; if(!file) return;
      const img = new Image(); img.src = URL.createObjectURL(file);
      img.onload = async ()=>{
        const canvas=document.getElementById('style-canvas');
        const ctx=canvas.getContext('2d');
        canvas.width=img.width; canvas.height=img.height;
        ctx.drawImage(img,0,0,img.width,img.height);
        if(!bodyPixModel) bodyPixModel=await bodyPix.load();
        const segmentation = await bodyPixModel.segmentPerson(img);
        const mask = bodyPix.toMask(segmentation);
        bodyPix.drawMask(canvas,img,mask,0.7,5,false);
        document.getElementById('style-output').innerText="Applied AI mask style transfer!";
      };
    });
  </script>
</body>
</html>
